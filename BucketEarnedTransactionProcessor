CREATE TABLE bucket_earned_transactions (
    tran_id int8 NOT NULL,
    bucket_type varchar(50) NOT NULL,
    category varchar(50) NOT NULL,
    earning_bucket_main_id varchar(50) NOT NULL, -- CREATE INDEX ix_earning_bucket_main_id ON earning_bucket (main_id);
    gaming_dt date NOT NULL,
    acct varchar(50) NOT NULL,
    earned numeric(14, 4) NOT NULL,
    last_modified_date timestamp NOT NULL DEFAULT now(),
    earning_rule_id varchar(50) NOT NULL,
    is_void bool NOT NULL DEFAULT false,
    CONSTRAINT pk_bucket_earned_transactions PRIMARY KEY (tran_id, category, bucket_type, earning_bucket_main_id)
);

CREATE INDEX bucket_earned_transactions_acct_idx ON mcrm_earning.bucket_earned_transactions USING btree (acct) WHERE (NOT is_void);
CREATE INDEX bucket_earned_transactions_gaming_dt_idx ON mcrm_earning.bucket_earned_transactions USING brin (gaming_dt, acct) WHERE (NOT is_void);

-- 新table
CREATE TABLE bucket_acct (
    acct varchar(50) NOT NULL,
	bucket_type varchar(50) NOT NULL,
    earning_bucket_main_id varchar(50) NOT NULL, -- CREATE INDEX ix_earning_bucket_main_id ON earning_bucket (main_id);
	earned numeric(14, 4) NOT NULL,
    remaining numeric(14, 4) NOT NULL,
    last_modified_date timestamp NOT NULL DEFAULT now(),
    is_used bool GENERATED ALWAYS AS (remaining <= 0) STORED,
    CONSTRAINT pk_bucket_acct PRIMARY KEY (acct, bucket_type, earning_bucket_main_id)
);

CREATE TABLE bucket_total_balances (
    acct varchar(50) NOT NULL,
	-- '{"point": 0, "dollar": 0, "comp": 0, "mcomp": 0}'
	-- point, dollar, comp, mcomp是屬於bucket_type的一種
    total_balances jsonb NOT NULL,
    last_modified_date timestamp NOT NULL DEFAULT now(),
    CONSTRAINT pk_bucket_total_balances PRIMARY KEY (acct)
);


現在我有一個acct的earning transaction records, 使用postgres, 用C#寫
0. 傳入的參數是bucket_earned_transactions的entity model
1. bucket_earned_transactions表是流水表, 如果傳入的參數tran_id conflict的話(即primary key相同), 就自動update以下欄位(gaming_dt, earned, last_modified_date), 不然就insert
2. 對於bucket_acct表, 如果conflict的話(即primary key相同), 就自動update以下欄位(新的earned=現有earned+bucket_earned_transactions的earned, 新的remaining=新的remaining+bucket_earned_transactions的earned, last_modified_date), 不然就insert
3. 對於bucket_total_balances表, 如果conflict的話(即primary key相同), 就自動update total_balances欄位, 根據傳進來的參數bucket_type, 如果現在的jsonb存在bucket_type, 就自動加earned, 如果現有不存在bucket_type, 就自己在jsonb加上一個field. 不然就insert records




using System;
using System.Collections.Generic;
using System.Data;
using System.Linq;
using System.Threading.Tasks;
using Npgsql;
using NpgsqlTypes;
using Newtonsoft.Json.Linq;

/// <summary>
/// Data model representing a single earning transaction record.
/// Make sure that BucketEarnedTransaction fields (e.g., EarningBucketMainId)
/// match the PostgreSQL table definitions exactly.
/// </summary>
public class BucketEarnedTransaction
{
    public long TranId { get; set; }
    public string Category { get; set; }
    public string BucketType { get; set; }
    public string EarningBucketMainId { get; set; } // Matches varchar(50) in the database
    public DateTime GamingDt { get; set; }
    public string Acct { get; set; }
    public decimal Earned { get; set; }
    public string EarningRuleId { get; set; }
    public bool IsVoid { get; set; }
}

/// <summary>
/// This class provides methods to batch-process BucketEarnedTransaction records
/// against three PostgreSQL tables:
///   1. bucket_earned_transactions
///   2. bucket_acct
///   3. bucket_total_balances
///
/// The approach uses "UPSERT" (INSERT ... ON CONFLICT) to either insert new rows
/// or update existing rows in an atomic way. We also group multiple operations into
/// batched transactions to improve performance under high concurrency scenarios.
/// </summary>
public class BucketEarnedTransactionProcessor
{
    /// <summary>
    /// Entry method to process a large list of BucketEarnedTransaction records in smaller batches.
    /// Each batch will be processed using a single database transaction. We can fine-tune batchSize
    /// for performance and concurrency.
    /// </summary>
    /// <param name="connectionString">The PostgreSQL connection string.</param>
    /// <param name="transactions">A list of BucketEarnedTransaction records to process.</param>
    /// <returns>Task representing the asynchronous operation.</returns>
    public async Task ProcessBucketEarnedTransactionBatchAsync(
        string connectionString,
        List<BucketEarnedTransaction> transactions)
    {
        // Adjust this batchSize based on performance testing and concurrency requirements.
        // A larger batch reduces round-trips but also increases potential locking during the transaction.
        int batchSize = 100;

        // Split the entire list of transactions into smaller batches of batchSize.
        var batches = transactions
            .Select((t, idx) => new { t, idx })
            .GroupBy(x => x.idx / batchSize)
            .Select(g => g.Select(x => x.t).ToList())
            .ToList();

        using (var conn = new NpgsqlConnection(connectionString))
        {
            await conn.OpenAsync();

            // Process each batch in sequence. Depending on your requirements, you might process
            // them in parallel, but usually sequential processing is simpler for transactional integrity.
            foreach (var batch in batches)
            {
                await ProcessBatchAsync(conn, batch);
            }
        }
    }

    /// <summary>
    /// Processes a single batch of transactions within a single transaction scope.  
    /// Stages:
    ///   Step 1: Upsert into bucket_earned_transactions  
    ///   Step 2: Upsert into bucket_acct  
    ///   Step 3: Upsert/merge JSON data into bucket_total_balances  
    /// 
    /// We use parameterized SQL with INSERT ... SELECT FROM unnest() to insert multiple rows at once,
    /// and ON CONFLICT to handle updates if a row with the same primary key(s) already exists.
    /// </summary>
    /// <param name="conn">An open NpgsqlConnection instance.</param>
    /// <param name="batch">A subset of BucketEarnedTransaction records.</param>
    /// <returns>Task representing the asynchronous batch operation.</returns>
    private async Task ProcessBatchAsync(NpgsqlConnection conn, List<BucketEarnedTransaction> batch)
    {
        // We choose IsolationLevel.ReadCommitted as a baseline. Adjust if stricter isolation is needed.
        // Also consider splitting each step into its own transaction if that better fits your concurrency needs.
        using var tran = await conn.BeginTransactionAsync(IsolationLevel.ReadCommitted);
        try
        {
            // ----------------------------------------------------------------------
            // Step 1: UPSERT bucket_earned_transactions
            // ----------------------------------------------------------------------
            // "bucket_earned_transactions" is a kind of transaction log table.
            // If a row with the same primary key exists, we update certain fields; otherwise we insert.
            var now = DateTime.Now;  // Or use DateTime.UtcNow for a universal timestamp

            string upsertBucketEarnedTransactionsSql = @"
INSERT INTO bucket_earned_transactions
    (tran_id, category, bucket_type, earning_bucket_main_id, gaming_dt, acct, earned, last_modified_date, earning_rule_id, is_void)
SELECT *
FROM unnest(
    @tran_id_list::bigint[],
    @category_list::varchar[],
    @bucket_type_list::varchar[],
    @earning_bucket_main_id_list::varchar[],
    @gaming_dt_list::date[],
    @acct_list::varchar[],
    @earned_list::numeric[],
    @last_modified_date_list::timestamp[],
    @earning_rule_id_list::varchar[],
    @is_void_list::boolean[]
) AS t(tran_id, category, bucket_type, earning_bucket_main_id, gaming_dt, acct, earned, last_modified_date, earning_rule_id, is_void)
ON CONFLICT ON CONSTRAINT pk_bucket_earned_transactions
DO UPDATE
    SET gaming_dt = EXCLUDED.gaming_dt,
        earned = EXCLUDED.earned,
        last_modified_date = EXCLUDED.last_modified_date
    WHERE bucket_earned_transactions.tran_id = EXCLUDED.tran_id
      AND bucket_earned_transactions.category = EXCLUDED.category
      AND bucket_earned_transactions.bucket_type = EXCLUDED.bucket_type
      AND bucket_earned_transactions.earning_bucket_main_id = EXCLUDED.earning_bucket_main_id;
";
            using (var cmd = new NpgsqlCommand(upsertBucketEarnedTransactionsSql, conn, tran))
            {
                cmd.Parameters.AddWithValue("tran_id_list", batch.Select(t => t.TranId).ToArray());
                cmd.Parameters.AddWithValue("category_list", batch.Select(t => t.Category ?? "").ToArray());
                cmd.Parameters.AddWithValue("bucket_type_list", batch.Select(t => t.BucketType ?? "").ToArray());
                cmd.Parameters.AddWithValue("earning_bucket_main_id_list",
                    batch.Select(t => (object)(t.EarningBucketMainId ?? "")).ToArray());
                cmd.Parameters.AddWithValue("gaming_dt_list", batch.Select(t => t.GamingDt).ToArray());
                cmd.Parameters.AddWithValue("acct_list", batch.Select(t => t.Acct ?? "").ToArray());
                cmd.Parameters.AddWithValue("earned_list", batch.Select(t => t.Earned).ToArray());
                cmd.Parameters.AddWithValue("last_modified_date_list",
                    Enumerable.Repeat(now, batch.Count).ToArray());
                cmd.Parameters.AddWithValue("earning_rule_id_list",
                    batch.Select(t => t.EarningRuleId ?? "").ToArray());
                cmd.Parameters.AddWithValue("is_void_list", batch.Select(t => t.IsVoid).ToArray());

                await cmd.ExecuteNonQueryAsync();
            }

            // ----------------------------------------------------------------------
            // Step 2: UPSERT bucket_acct
            // ----------------------------------------------------------------------
            // "bucket_acct" holds aggregated data for each (acct, bucket_type, earning_bucket_main_id).
            // We sum up Earned amounts for each group in the batch and then do an upsert.
            // If the row already exists, we add to the existing 'earned' and 'remaining' columns.
            now = DateTime.Now;  // Reuse the same timestamp logic as needed

            var acctGroups = batch
                .GroupBy(t => new { t.Acct, t.BucketType, t.EarningBucketMainId })
                .Select(g => new
                {
                    Acct = g.Key.Acct,
                    BucketType = g.Key.BucketType,
                    EarningBucketMainId = g.Key.EarningBucketMainId,
                    EarnedSum = g.Sum(x => x.Earned)
                })
                .ToList();

            string upsertBucketAcctSql = @"
INSERT INTO bucket_acct
    (acct, bucket_type, earning_bucket_main_id, earned, remaining, last_modified_date)
SELECT *
FROM unnest(
    @acct_list::varchar[],
    @bucket_type_list::varchar[],
    @earning_bucket_main_id_list::varchar[],
    @earned_list::numeric[],
    @remaining_list::numeric[],
    @last_modified_date_list::timestamp[]
) AS t(acct, bucket_type, earning_bucket_main_id, earned, remaining, last_modified_date)
ON CONFLICT ON CONSTRAINT pk_bucket_acct
DO UPDATE
    SET earned = bucket_acct.earned + EXCLUDED.earned,
        remaining = bucket_acct.remaining + EXCLUDED.remaining,
        last_modified_date = EXCLUDED.last_modified_date;
";
            using (var cmd = new NpgsqlCommand(upsertBucketAcctSql, conn, tran))
            {
                cmd.Parameters.AddWithValue("acct_list", acctGroups.Select(g => g.Acct ?? "").ToArray());
                cmd.Parameters.AddWithValue("bucket_type_list", acctGroups.Select(g => g.BucketType ?? "").ToArray());
                cmd.Parameters.AddWithValue("earning_bucket_main_id_list",
                    acctGroups.Select(g => (object)(g.EarningBucketMainId ?? "")).ToArray());
                cmd.Parameters.AddWithValue("earned_list", acctGroups.Select(g => g.EarnedSum).ToArray());
                cmd.Parameters.AddWithValue("remaining_list", acctGroups.Select(g => g.EarnedSum).ToArray());
                cmd.Parameters.AddWithValue("last_modified_date_list",
                    Enumerable.Repeat(now, acctGroups.Count).ToArray());

                await cmd.ExecuteNonQueryAsync();
            }

            // ----------------------------------------------------------------------
            // Step 3: UPSERT bucket_total_balances (JSONB column)
            // ----------------------------------------------------------------------
            // This table holds total balances in a JSONB field keyed by bucket types.
            // The batch might contain multiple records for the same acct and bucket_type,
            // so we group them first, then merge them into the JSONB column using the "||" operator.
            now = DateTime.Now;  // Another timestamp (or reuse the same as above)

            var balanceGroups = batch
                .GroupBy(t => t.Acct)
                .Select(g => new
                {
                    Acct = g.Key,
                    BucketTypeAmounts = g
                        .GroupBy(x => x.BucketType)
                        .ToDictionary(gg => gg.Key, gg => gg.Sum(x => x.Earned))
                })
                .ToList();

            // Prepare arrays for the batched INSERT ... SELECT FROM unnest(...) approach
            var acctList = new List<string>();
            var balancesList = new List<string>();
            var lastModifiedList = new List<DateTime>();

            foreach (var group in balanceGroups)
            {
                // Construct a JSON object that maps bucketType -> total Earned
                var totalBalancesJson = new JObject();
                foreach (var kvp in group.BucketTypeAmounts)
                {
                    totalBalancesJson[kvp.Key] = kvp.Value;
                }

                acctList.Add(group.Acct ?? "");
                balancesList.Add(totalBalancesJson.ToString());
                lastModifiedList.Add(now);
            }

            // We merge the new partial JSON with existing total_balances using the "||" operator.
            // On conflict, we update the JSONB field: (existing JSON) || (new JSON).
            string upsertBucketTotalBalancesSql = @"
INSERT INTO bucket_total_balances (acct, total_balances, last_modified_date)
SELECT t.acct, t.total_balances, t.last_modified_date
FROM unnest(
    @acct_list::varchar[],
    @total_balances_list::jsonb[],
    @last_modified_date_list::timestamp[]
) AS t(acct, total_balances, last_modified_date)
ON CONFLICT (acct)
DO UPDATE
    SET total_balances = bucket_total_balances.total_balances || EXCLUDED.total_balances,
        last_modified_date = EXCLUDED.last_modified_date;
";
            using (var cmd = new NpgsqlCommand(upsertBucketTotalBalancesSql, conn, tran))
            {
                // We must specify NpgsqlDbType.Array | NpgsqlDbType.Jsonb to send an array of JSONB
                cmd.Parameters.AddWithValue("acct_list", acctList.ToArray());
                cmd.Parameters.Add(new NpgsqlParameter("total_balances_list", NpgsqlDbType.Array | NpgsqlDbType.Jsonb)
                {
                    Value = balancesList.ToArray()
                });
                cmd.Parameters.AddWithValue("last_modified_date_list", lastModifiedList.ToArray());

                await cmd.ExecuteNonQueryAsync();
            }

            // Commit the transaction if everything succeeds
            await tran.CommitAsync();
        }
        catch
        {
            // Rollback in case of any error during the batch operation.
            await tran.RollbackAsync();
            throw;
        }
    }
}
